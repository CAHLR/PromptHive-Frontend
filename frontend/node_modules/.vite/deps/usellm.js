import {
  require_react
} from "./chunk-HS5T2ZWL.js";
import {
  __toESM
} from "./chunk-AUZ3RYOM.js";

// node_modules/usellm/dist/esm/server/eventsource-parser.js
function createParser(onParse) {
  let isFirstChunk;
  let buffer;
  let startingPosition;
  let startingFieldLength;
  let eventId;
  let eventName;
  let data;
  reset();
  return { feed, reset };
  function reset() {
    isFirstChunk = true;
    buffer = "";
    startingPosition = 0;
    startingFieldLength = -1;
    eventId = void 0;
    eventName = void 0;
    data = "";
  }
  function feed(chunk) {
    buffer = buffer ? buffer + chunk : chunk;
    if (isFirstChunk && hasBom(buffer)) {
      buffer = buffer.slice(BOM.length);
    }
    isFirstChunk = false;
    const length = buffer.length;
    let position = 0;
    let discardTrailingNewline = false;
    while (position < length) {
      if (discardTrailingNewline) {
        if (buffer[position] === "\n") {
          ++position;
        }
        discardTrailingNewline = false;
      }
      let lineLength = -1;
      let fieldLength = startingFieldLength;
      let character;
      for (let index = startingPosition; lineLength < 0 && index < length; ++index) {
        character = buffer[index] || "";
        if (character === ":" && fieldLength < 0) {
          fieldLength = index - position;
        } else if (character === "\r") {
          discardTrailingNewline = true;
          lineLength = index - position;
        } else if (character === "\n") {
          lineLength = index - position;
        }
      }
      if (lineLength < 0) {
        startingPosition = length - position;
        startingFieldLength = fieldLength;
        break;
      } else {
        startingPosition = 0;
        startingFieldLength = -1;
      }
      parseEventStreamLine(buffer, position, fieldLength, lineLength);
      position += lineLength + 1;
    }
    if (position === length) {
      buffer = "";
    } else if (position > 0) {
      buffer = buffer.slice(position);
    }
  }
  function parseEventStreamLine(lineBuffer, index, fieldLength, lineLength) {
    if (lineLength === 0) {
      if (data.length > 0) {
        onParse({
          type: "event",
          id: eventId,
          event: eventName || void 0,
          data: data.slice(0, -1)
          // remove trailing newline
        });
        data = "";
        eventId = void 0;
      }
      eventName = void 0;
      return;
    }
    const noValue = fieldLength < 0;
    const field = lineBuffer.slice(index, index + (noValue ? lineLength : fieldLength));
    let step = 0;
    if (noValue) {
      step = lineLength;
    } else if (lineBuffer[index + fieldLength + 1] === " ") {
      step = fieldLength + 2;
    } else {
      step = fieldLength + 1;
    }
    const position = index + step;
    const valueLength = lineLength - step;
    const value = lineBuffer.slice(position, position + valueLength).toString();
    if (field === "data") {
      data += value ? `${value}
` : "\n";
    } else if (field === "event") {
      eventName = value;
    } else if (field === "id" && !value.includes("\0")) {
      eventId = value;
    } else if (field === "retry") {
      const retry = parseInt(value, 10);
      if (!Number.isNaN(retry)) {
        onParse({ type: "reconnect-interval", value: retry });
      }
    }
  }
}
var BOM = [239, 187, 191];
function hasBom(buffer) {
  return BOM.every((charCode, index) => buffer.charCodeAt(index) === charCode);
}

// node_modules/usellm/dist/esm/shared/utils.js
var CHAT_COMPLETIONS_API_URL = "https://api.openai.com/v1/chat/completions";
var AUDIO_TRANSCRIPTIONS_API_URL = "https://api.openai.com/v1/audio/transcriptions";
var EMBEDDINGS_API_URL = "https://api.openai.com/v1/embeddings";
var getTextToSpeechApiUrl = (voice_id) => `https://api.elevenlabs.io/v1/text-to-speech/${voice_id}`;
var ELVEN_LABS_DEFAULT_MODEL_ID = "eleven_monolingual_v1";
var ELVEN_LABS_DEFAULT_VOICE_ID = "21m00Tcm4TlvDq8ikWAM";
var IMAGE_GENERATION_API_URL = "https://api.openai.com/v1/images/generations";
var REPLICATE_API_URL = "https://api.replicate.com/v1/predictions";
var HUGGING_FACE_API_URL = "https://api-inference.huggingface.co/models/";
var EDIT_IMAGE_API_URL = "https://api.openai.com/v1/images/edits";
var IMAGE_VARIATIONS_API_URL = "https://api.openai.com/v1/images/variations";
var ResponseError = class extends Error {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "status", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
  }
};
function makeErrorResponse(message, status) {
  const error = new ResponseError(JSON.stringify({ message }));
  error.status = status || 500;
  return error;
}
async function streamOpenAIResponse(response, callback) {
  if (!response.body) {
    throw Error("Response has no body");
  }
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let done = false;
  let text = "";
  let isFirst = true;
  while (!done) {
    const { value, done: doneReading } = await reader.read();
    done = doneReading;
    const chunkValue = decoder.decode(value);
    text += chunkValue;
    const message2 = { content: text, role: "assistant" };
    callback && callback({ message: message2, isFirst, isLast: done });
    isFirst = false;
  }
  const message = { content: text, role: "assistant" };
  return { message };
}
function fillPrompt(str, data = {}) {
  return Object.entries(data).reduce((res, [key, value]) => {
    const mainRe = new RegExp(`(?<!\\\\){{\\s*${key}\\s*}}`, "g");
    const escapeRe = new RegExp(`\\\\({{\\s*${key}\\s*}})`, "g");
    return res.replace(mainRe, value.toString()).replace(escapeRe, "$1");
  }, str);
}
function dataURLToBlob(dataurl) {
  var _a;
  let arr = dataurl.split(",");
  if (!arr || arr.length < 2) {
    throw new Error("Invalid data URL");
  }
  let mimeMatch = (_a = arr[0]) === null || _a === void 0 ? void 0 : _a.match(/:(.*?);/);
  if (!mimeMatch || !arr[1]) {
    throw new Error("Invalid data URL");
  }
  let mime = mimeMatch[1], bstr = atob(arr[1]), n = bstr.length, u8arr = new Uint8Array(n);
  while (n--) {
    u8arr[n] = bstr.charCodeAt(n);
  }
  return new Blob([u8arr], { type: mime });
}
function dataUrlToExtension(dataURL) {
  var extension = "";
  if (dataURL.indexOf("/") !== -1 && dataURL.indexOf(";") !== -1) {
    var startIndex = dataURL.indexOf("/") + 1;
    var endIndex = dataURL.indexOf(";");
    extension = dataURL.substring(startIndex, endIndex);
  }
  return extension;
}
function dotProduct(vecA, vecB) {
  let product = 0;
  if (vecA.length !== vecB.length)
    throw new Error("Vectors must be same length");
  for (let i = 0; i < vecA.length; i++) {
    product += vecA[i] * vecB[i];
  }
  return product;
}
function magnitude(vec) {
  let sum = 0;
  for (let i = 0; i < vec.length; i++) {
    sum += vec[i] * vec[i];
  }
  return Math.sqrt(sum);
}
function cosineSimilarity(vecA, vecB) {
  return dotProduct(vecA, vecB) / (magnitude(vecA) * magnitude(vecB));
}
function scoreEmbeddings(options) {
  const { embeddings, query, top } = options;
  const scores = embeddings.map((vector) => cosineSimilarity(query, vector));
  const sortedScores = scores.map((score, index) => ({ score, index })).sort((a, b) => b.score - a.score).slice(0, top || void 0);
  return sortedScores;
}

// node_modules/usellm/dist/esm/server/OpenAIStream.js
var __asyncValues = function(o) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var m = o[Symbol.asyncIterator], i;
  return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
    return this;
  }, i);
  function verb(n) {
    i[n] = o[n] && function(v) {
      return new Promise(function(resolve, reject) {
        v = o[n](v), settle(resolve, reject, v.done, v.value);
      });
    };
  }
  function settle(resolve, reject, d, v) {
    Promise.resolve(v).then(function(v2) {
      resolve({ value: v2, done: d });
    }, reject);
  }
};
async function OpenAIStream(options) {
  const { body, openaiApiKey, fetcher = fetch } = options;
  const encoder = new TextEncoder();
  const decoder = new TextDecoder();
  const res = await fetcher(CHAT_COMPLETIONS_API_URL, {
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${openaiApiKey}`
    },
    method: "POST",
    body: JSON.stringify(body)
  });
  if (res.status != 200 || !res.body) {
    throw new Error(await res.text());
  }
  const stream = new ReadableStream({
    async start(controller) {
      var _a, e_1, _b, _c;
      const onParse = (event) => {
        if (event.type === "event") {
          const data = event.data;
          if (data === "[DONE]") {
            controller.close();
            return;
          }
          try {
            const json = JSON.parse(data);
            const text = json.choices[0].delta.content;
            const queue = encoder.encode(text);
            controller.enqueue(queue);
          } catch (e) {
            controller.error(e);
          }
        }
      };
      const parser = createParser(onParse);
      if (res.body) {
        try {
          for (var _d = true, _e = __asyncValues(res.body), _f; _f = await _e.next(), _a = _f.done, !_a; ) {
            _c = _f.value;
            _d = false;
            try {
              const chunk = _c;
              parser.feed(decoder.decode(chunk));
            } finally {
              _d = true;
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (!_d && !_a && (_b = _e.return))
              await _b.call(_e);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
      }
    }
  });
  return stream;
}

// node_modules/usellm/dist/esm/server/llm-service.js
var __rest = function(s, e) {
  var t = {};
  for (var p in s)
    if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
      t[p] = s[p];
  if (s != null && typeof Object.getOwnPropertySymbols === "function")
    for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
      if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
        t[p[i]] = s[p[i]];
    }
  return t;
};
var defaultTemplate = {
  model: "gpt-3.5-turbo",
  max_tokens: 1e3,
  temperature: 0.8
};
var LLMService = class {
  constructor({ openaiApiKey = "", elvenLabsApiKey = "", replicateApiKey = "", huggingFaceApiKey = "", fetcher = fetch, templates = {}, debug = false, isAllowed = () => true, actions = [] }) {
    Object.defineProperty(this, "templates", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "openaiApiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "elvenLabsApiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "replicateApiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "huggingFaceApiKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "fetcher", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "debug", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "actions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "isAllowed", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "customActions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "cosineSimilarity", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: cosineSimilarity
    });
    Object.defineProperty(this, "scoreEmbeddings", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: scoreEmbeddings
    });
    this.openaiApiKey = openaiApiKey;
    this.elvenLabsApiKey = elvenLabsApiKey;
    this.replicateApiKey = replicateApiKey;
    this.huggingFaceApiKey = huggingFaceApiKey;
    this.fetcher = fetcher;
    this.templates = templates;
    this.debug = debug;
    this.isAllowed = isAllowed;
    this.actions = actions;
  }
  registerTemplate(template) {
    this.templates[template.id] = template;
  }
  registerAction(id, action) {
    this.customActions[id] = action;
  }
  async callAction(action, body = {}) {
    if (!this.actions.includes(action) && !this.customActions[action]) {
      throw makeErrorResponse(`Action "${action}" is not allowed`, 400);
    }
    if (action === "chat") {
      return this.chat(body);
    }
    if (action === "transcribe") {
      return this.transcribe(body);
    }
    if (action === "embed") {
      return this.embed(body);
    }
    if (action === "speak") {
      return this.speak(body);
    }
    if (action === "generateImage") {
      return this.generateImage(body);
    }
    if (action === "editImage") {
      return this.editImage(body);
    }
    if (action === "imageVariation") {
      return this.imageVariation(body);
    }
    if (action === "voiceChat") {
      return this.voiceChat(body);
    }
    if (action === "callReplicate") {
      return this.callReplicate(body);
    }
    if (action === "callHuggingFace") {
      return this.callHuggingFace(body);
    }
    const actionFunc = this.customActions[action];
    if (!actionFunc) {
      throw makeErrorResponse(`Action "${action}" is not supported`, 400);
    }
    return actionFunc(body);
  }
  prepareChatBody(body) {
    const template = Object.assign(Object.assign({}, defaultTemplate), this.templates[body.template || ""] || {});
    let filledMessages = [];
    if (template.systemPrompt) {
      filledMessages.push({
        role: "system",
        content: fillPrompt(template.systemPrompt, body.inputs)
      });
    }
    if (template.userPrompt) {
      filledMessages.push({
        role: "user",
        content: fillPrompt(template.userPrompt, body.inputs)
      });
    }
    if (body.messages) {
      body.messages.forEach((message) => {
        filledMessages.push({
          role: message.role,
          content: message.content,
          user: message.user
        });
      });
    }
    if (filledMessages.length == 0) {
      throw makeErrorResponse("Empty message list. Please provide at least one message!", 400);
    }
    const preparedBody = {
      messages: filledMessages,
      stream: body.stream,
      user: body.user,
      model: template.model,
      temperature: template.temperature,
      top_p: template.top_p,
      n: template.n,
      max_tokens: template.max_tokens,
      presence_penalty: template.presence_penalty,
      frequency_penalty: template.frequency_penalty,
      logit_bias: template.logit_bias
    };
    return preparedBody;
  }
  async handle({ body = {}, request }) {
    if (!await this.isAllowed({ body, request })) {
      throw makeErrorResponse("Request not allowed", 405);
    }
    if (!this.openaiApiKey) {
      throw makeErrorResponse("OpenAI API key is required.", 400);
    }
    if (!("$action" in body)) {
      throw makeErrorResponse("`handle` expects a key $action in the body", 400);
    }
    const { $action } = body, rest = __rest(body, ["$action"]);
    const result = await this.callAction($action, rest);
    if ("stream" in body && body.stream) {
      return result;
    }
    return { result: JSON.stringify(result) };
  }
  async chat(body) {
    const preparedBody = this.prepareChatBody(body);
    if (this.debug) {
      console.log("[LLMService] preparedBody", preparedBody);
    }
    if (preparedBody.stream) {
      const result = await OpenAIStream({
        body: preparedBody,
        openaiApiKey: this.openaiApiKey,
        fetcher: this.fetcher
      });
      return { result };
    } else {
      const response = await this.fetcher(CHAT_COMPLETIONS_API_URL, {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${this.openaiApiKey}`
        },
        method: "POST",
        body: JSON.stringify(preparedBody)
      });
      if (!response.ok) {
        throw new Error(await response.text());
      }
      return response.json();
    }
  }
  async embed(options) {
    const { input, user } = options;
    const model = "text-embedding-ada-002";
    if (!input) {
      throw makeErrorResponse("'input' is required", 400);
    }
    if (typeof input !== "string" && !Array.isArray(input)) {
      throw makeErrorResponse("'input' must be a string or a list of strings", 400);
    }
    let santizedInput;
    if (typeof input === "string") {
      santizedInput = input.trim();
    } else {
      santizedInput = input.map((s) => {
        const trimmed = s.trim();
        if (!trimmed) {
          throw makeErrorResponse("'input' must not contain any empty strings");
        }
        return s.trim();
      });
    }
    if (santizedInput.length === 0) {
      throw makeErrorResponse("'input' must not be empty", 400);
    }
    const response = await this.fetcher(EMBEDDINGS_API_URL, {
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${this.openaiApiKey}`
      },
      method: "POST",
      body: JSON.stringify({ input, user, model })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    const { data } = await response.json();
    const embeddings = data.map((d) => d.embedding);
    return { embeddings };
  }
  async transcribe(options) {
    const { audioUrl, language, prompt } = options;
    if (!audioUrl) {
      throw makeErrorResponse("'audioUrl' is required", 400);
    }
    const audioBlob = dataURLToBlob(audioUrl);
    const formData = new FormData();
    formData.append("file", audioBlob, "recording.wav");
    formData.append("model", "whisper-1");
    if (language) {
      formData.append("language", language);
    }
    if (prompt) {
      formData.append("prompt", prompt);
    }
    const response = await this.fetcher(AUDIO_TRANSCRIPTIONS_API_URL, {
      method: "POST",
      body: formData,
      headers: {
        Authorization: `Bearer ${this.openaiApiKey}`
      }
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async speak(options) {
    const { text, model_id = ELVEN_LABS_DEFAULT_MODEL_ID, voice_id = ELVEN_LABS_DEFAULT_VOICE_ID, voice_settings } = options;
    const response = await this.fetcher(getTextToSpeechApiUrl(voice_id), {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "xi-api-key": this.elvenLabsApiKey
      },
      body: JSON.stringify({
        text,
        model_id,
        voice_settings
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    const responseBlob = await response.blob();
    const responseBuffer = Buffer.from(await responseBlob.arrayBuffer());
    const audioUrl = "data:" + responseBlob.type + ";base64," + responseBuffer.toString("base64");
    return { audioUrl };
  }
  async generateImage(options) {
    const { prompt, n = 1, size = "256x256" } = options;
    if (!prompt) {
      throw makeErrorResponse("'prompt' is required", 400);
    }
    const response = await this.fetcher(IMAGE_GENERATION_API_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${this.openaiApiKey}`
      },
      body: JSON.stringify({
        prompt,
        n: Math.min(n, 4),
        size,
        response_format: "url"
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    const { data } = await response.json();
    const images = data.map((d) => d.url || d.b64_json);
    return { images };
  }
  async editImage(options) {
    const { image, mask, prompt, n, size, user } = options;
    const formData = new FormData();
    formData.append("image", dataURLToBlob(image), `image.${dataUrlToExtension(image)}`);
    mask && formData.append("mask", dataURLToBlob(mask), `mask.${dataUrlToExtension(mask)}`);
    prompt && formData.append("prompt", prompt);
    n && formData.append("n", Math.max(n, 4).toString());
    size && formData.append("size", size);
    user && formData.append("user", user);
    const response = await this.fetcher(EDIT_IMAGE_API_URL, {
      method: "POST",
      body: formData,
      headers: {
        Authorization: `Bearer ${this.openaiApiKey}`
      }
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    const { data } = await response.json();
    const images = data.map((d) => d.url || d.b64_json);
    return { images };
  }
  async imageVariation(options) {
    const { image, n, size, user } = options;
    const formData = new FormData();
    formData.append("image", dataURLToBlob(image), `image.${dataUrlToExtension(image)}`);
    n && formData.append("n", Math.max(n, 4).toString());
    size && formData.append("size", size);
    user && formData.append("user", user);
    const response = await this.fetcher(IMAGE_VARIATIONS_API_URL, {
      method: "POST",
      body: formData,
      headers: {
        Authorization: `Bearer ${this.openaiApiKey}`
      }
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    const { data } = await response.json();
    const images = data.map((d) => d.url || d.b64_json);
    return { images };
  }
  async voiceChat(options) {
    const { transcribeAudioUrl, transcribeLanguage, transcribePrompt } = options;
    const { text } = await this.transcribe({
      audioUrl: transcribeAudioUrl,
      language: transcribeLanguage,
      prompt: transcribePrompt
    });
    const { chatMessages, chatTemplate, chatInputs } = options;
    const messages = [...chatMessages || [], { role: "user", content: text }];
    const chatResult = await this.chat({
      messages,
      template: chatTemplate,
      inputs: chatInputs
    });
    const { choices } = chatResult;
    const { speakModelId, speechVoideId, speechVoiceSettings } = options;
    const { audioUrl } = await this.speak({
      text: choices[0].message.content,
      model_id: speakModelId,
      voice_id: speechVoideId,
      voice_settings: speechVoiceSettings
    });
    return {
      audioUrl,
      messages: [
        { role: "user", content: text },
        { role: "assistant", content: choices[0].message.content }
      ]
    };
  }
  async callReplicate(options) {
    const { version, input, timeout = 1e4 } = options;
    if (!input) {
      throw makeErrorResponse("'input' is required", 400);
    }
    const createPredictionResponse = await this.fetcher(REPLICATE_API_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Token ${this.replicateApiKey}`
      },
      body: JSON.stringify({
        version,
        input
      })
    });
    if (!createPredictionResponse.ok) {
      throw makeErrorResponse(await createPredictionResponse.text());
    }
    const { id: prediction_id } = await createPredictionResponse.json();
    const GET_PREDICTION_URL = REPLICATE_API_URL + "/" + prediction_id;
    const sleep = async (milliseconds) => {
      await new Promise((resolve) => {
        return setTimeout(resolve, milliseconds);
      });
    };
    await sleep(timeout);
    const statusResponse = await this.fetcher(GET_PREDICTION_URL, {
      method: "GET",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Token ${this.replicateApiKey}`
      }
    });
    if (!statusResponse.ok) {
      throw new Error(await statusResponse.text());
    }
    const getResponse = await statusResponse.json();
    if (getResponse && getResponse.status === "succeeded") {
      return {
        id: getResponse.id,
        urls: getResponse.urls,
        status: getResponse.status,
        output: getResponse.output,
        metrics: getResponse.metrics
      };
    } else {
      return {
        output: "Training Not Completed! Please increase the value of timeout and try again."
      };
    }
  }
  async callHuggingFace(options) {
    const { data, model } = options;
    const link = HUGGING_FACE_API_URL + model;
    const response = await this.fetcher(link, {
      method: "POST",
      headers: { Authourization: `Bearer ${this.huggingFaceApiKey}` },
      body: JSON.stringify(data)
    });
    if (!response.ok) {
      throw makeErrorResponse(await response.text());
    }
    const result = await response.json();
    return result;
  }
};
function createLLMService(options = {}) {
  return new LLMService(options);
}

// node_modules/usellm/dist/esm/client/usellm.js
var import_react2 = __toESM(require_react());

// node_modules/usellm/dist/esm/client/llm-provider.js
var import_react = __toESM(require_react());
var LLMContext = (0, import_react.createContext)({});
function LLMProvider({ children, serviceUrl }) {
  return (0, import_react.createElement)(LLMContext.Provider, { value: { serviceUrl } }, children);
}

// node_modules/usellm/dist/esm/client/usellm.js
function useLLM({ serviceUrl: argServiceUrl, fetcher = fetch } = {}) {
  const { serviceUrl: contextServiceUrl } = (0, import_react2.useContext)(LLMContext);
  const serviceUrl = argServiceUrl || contextServiceUrl || "";
  if (!serviceUrl) {
    throw new Error("No serviceUrl provided. Provide one or use LLMProvider to set it globally.");
  }
  async function chat({ messages = [], stream = false, template, inputs, onStream }) {
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages,
        stream,
        $action: "chat",
        template,
        inputs
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    if (stream) {
      return streamOpenAIResponse(response, onStream);
    } else {
      const resJson = await response.json();
      const message = resJson.choices[0].message;
      return { message };
    }
  }
  const recordingRef = (0, import_react2.useRef)(null);
  async function record({ deviceId } = {}) {
    const audioStream = await navigator.mediaDevices.getUserMedia({
      audio: deviceId ? { deviceId } : true
    });
    const mediaRecorder = new MediaRecorder(audioStream);
    const audioChunks = [];
    recordingRef.current = { mediaRecorder, audioChunks, audioStream };
    mediaRecorder.addEventListener("dataavailable", (event) => {
      audioChunks.push(event.data);
    });
    mediaRecorder.start();
  }
  async function stopRecording() {
    return new Promise((resolve, reject) => {
      if (!recordingRef.current) {
        reject("No recording in progress");
        return;
      }
      const { mediaRecorder, audioChunks, audioStream } = recordingRef.current;
      mediaRecorder.addEventListener("stop", () => {
        const audioBlob = new Blob(audioChunks, {
          type: "audio/ogg; codecs=opus"
        });
        const reader = new FileReader();
        reader.onloadend = () => {
          const base64data = reader.result;
          resolve({ audioUrl: base64data });
        };
        reader.readAsDataURL(audioBlob);
      });
      mediaRecorder.stop();
      audioStream.getTracks().forEach((track) => track.stop());
    });
  }
  async function transcribe({ audioUrl, language, prompt }) {
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        audioUrl,
        language,
        prompt,
        $action: "transcribe"
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function embed({ input, user }) {
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        input,
        user,
        $action: "embed"
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function speak(options) {
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(Object.assign(Object.assign({}, options), { $action: "speak" }))
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function generateImage(options) {
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(Object.assign(Object.assign({}, options), { $action: "generateImage" }))
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function editImage(options) {
    const { imageUrl, maskUrl, prompt, n, size } = options;
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        prompt,
        n,
        size,
        image: imageUrl,
        mask: maskUrl,
        $action: "editImage"
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function imageVariation(options) {
    const { imageUrl, n, size } = options;
    const response = await fetcher(`${serviceUrl}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        image: imageUrl,
        n,
        size,
        $action: "imageVariation"
      })
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function fileToDataURL(file) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result);
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  }
  async function imageToDataURL(file) {
    return new Promise((resolve, reject) => {
      const img = new Image();
      img.src = URL.createObjectURL(file);
      img.onload = () => {
        const canvas = document.createElement("canvas");
        canvas.width = img.width;
        canvas.height = img.height;
        const ctx = canvas.getContext("2d");
        ctx === null || ctx === void 0 ? void 0 : ctx.drawImage(img, 0, 0, img.width, img.height);
        const dataUrl = canvas.toDataURL("image/png");
        resolve(dataUrl);
      };
      img.onerror = reject;
    });
  }
  async function voiceChat(options) {
    return callAction("voiceChat", options);
  }
  async function callAction(action, options) {
    const response = await fetcher(serviceUrl, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(Object.assign(Object.assign({}, options), { $action: action }))
    });
    if (!response.ok) {
      throw new Error(await response.text());
    }
    return response.json();
  }
  async function callReplicate(options) {
    return callAction("callReplicate", options);
  }
  async function callHuggingFace(options) {
    return callAction("callHuggingFace", options);
  }
  return {
    callAction,
    chat,
    voiceChat,
    record,
    stopRecording,
    transcribe,
    embed,
    cosineSimilarity,
    scoreEmbeddings,
    speak,
    generateImage,
    fileToDataURL,
    imageToDataURL,
    editImage,
    imageVariation,
    callReplicate,
    callHuggingFace
  };
}

// node_modules/usellm/dist/esm/index.js
var esm_default = useLLM;
export {
  LLMProvider,
  createLLMService,
  esm_default as default
};
//# sourceMappingURL=usellm.js.map
